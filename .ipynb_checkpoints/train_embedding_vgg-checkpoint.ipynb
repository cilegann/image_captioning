{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Input, LSTM, Dense,Activation,Embedding,merge\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import concatenate,Reshape,Concatenate,RepeatVector\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from keras.callbacks import EarlyStopping\n",
    "import random\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from keras import backend as K\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_json='./data/dataset_coco.json'\n",
    "tokenfile='./tokenv2.pkl'\n",
    "detokenfile='./detokenv2.pkl'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "session = tf.Session(config=config)\n",
    "KTF.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(coco_json) as file:\n",
    "    lines=file.readlines()\n",
    "data=json.loads(lines[0])['images']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'filepath': 'val2014', 'imgid': 0, 'sentences': [{'imgid': 0, 'raw': 'A man with a red helmet on a small moped on a dirt road. ', 'sentid': 770337, 'tokens': ['a', 'man', 'with', 'a', 'red', 'helmet', 'on', 'a', 'small', 'moped', 'on', 'a', 'dirt', 'road']}, {'imgid': 0, 'raw': 'Man riding a motor bike on a dirt road on the countryside.', 'sentid': 771687, 'tokens': ['man', 'riding', 'a', 'motor', 'bike', 'on', 'a', 'dirt', 'road', 'on', 'the', 'countryside']}, {'imgid': 0, 'raw': 'A man riding on the back of a motorcycle.', 'sentid': 772707, 'tokens': ['a', 'man', 'riding', 'on', 'the', 'back', 'of', 'a', 'motorcycle']}, {'imgid': 0, 'raw': 'A dirt path with a young person on a motor bike rests to the foreground of a verdant area with a bridge and a background of cloud-wreathed mountains. ', 'sentid': 776154, 'tokens': ['a', 'dirt', 'path', 'with', 'a', 'young', 'person', 'on', 'a', 'motor', 'bike', 'rests', 'to', 'the', 'foreground', 'of', 'a', 'verdant', 'area', 'with', 'a', 'bridge', 'and', 'a', 'background', 'of', 'cloud', 'wreathed', 'mountains']}, {'imgid': 0, 'raw': 'A man in a red shirt and a red hat is on a motorcycle on a hill side.', 'sentid': 781998, 'tokens': ['a', 'man', 'in', 'a', 'red', 'shirt', 'and', 'a', 'red', 'hat', 'is', 'on', 'a', 'motorcycle', 'on', 'a', 'hill', 'side']}], 'split': 'test', 'cocoid': 391895, 'sentids': [770337, 771687, 772707, 776154, 781998], 'filename': 'COCO_val2014_000000391895.jpg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_file=[]\n",
    "train_y_seq=[]\n",
    "vali_x_file=[]\n",
    "vali_y_seq=[]\n",
    "token={}\n",
    "if os.path.exists(tokenfile):\n",
    "    with open(tokenfile,'rb') as file:\n",
    "        token=pickle.load(file)\n",
    "else:\n",
    "    token['\\t']=1\n",
    "    token['\\n']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    if d['split']=='train':\n",
    "        train_x_file.append('./coco/'+d['filepath']+'/'+d['filename'])\n",
    "        seq=d['sentences'][0]['tokens']\n",
    "        for s in seq:\n",
    "            if s not in token:\n",
    "                token[s]=len(token)+1\n",
    "        train_y_seq.append(['\\t']+seq+['\\n'])\n",
    "    if d['split']=='test':\n",
    "        vali_x_file.append('./coco/'+d['filepath']+'/'+d['filename'])\n",
    "        seq=d['sentences'][0]['tokens']\n",
    "        for s in seq:\n",
    "            if s not in token:\n",
    "                token[s]=len(token)+1\n",
    "        vali_y_seq.append(['\\t']+seq+['\\n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of train: 82783\n",
      "Num of vali: 5000\n",
      "Num of token: 11857\n",
      "Len of vector: 25088\n"
     ]
    }
   ],
   "source": [
    "with open(tokenfile,'wb') as file:\n",
    "    pickle.dump(token,file)\n",
    "    \n",
    "num_tokens=len(token)\n",
    "batch_size=1\n",
    "seq_len=49+2 #49+'\\t'+'\\n'\n",
    "vec_len=25088\n",
    "print(\"Num of train:\",len(train_x_file))\n",
    "print(\"Num of vali:\",len(vali_x_file))\n",
    "print(\"Num of token:\",num_tokens)\n",
    "print(\"Len of vector:\",vec_len)\n",
    "c = list(zip(train_x_file, train_y_seq))\n",
    "\n",
    "random.shuffle(c)\n",
    "\n",
    "train_x_file, train_y_seq = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_reader(path):\n",
    "    with open(path,'r') as f:\n",
    "        line=f.readline()\n",
    "        vector=np.asarray( list(map(float,line.split(\",\")[1].split(\" \"))) )\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggmodel = VGG16(weights='imagenet', include_top=False)\n",
    "def vggextract(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return np.reshape(vggmodel.predict(x),(25088))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=vggextract('./file/000001.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataGenerator(x,y):\n",
    "    while(1):\n",
    "        decoder_input_data=[]\n",
    "        decoder_target_data=[]\n",
    "        encoder_input_data=[]\n",
    "        for index in range(len(x)):\n",
    "            for t,word in enumerate(y[index]):\n",
    "                if t>0:\n",
    "                    did=np.zeros(\n",
    "                        (seq_len),dtype='float32'\n",
    "                    )\n",
    "                    dtd=np.zeros(\n",
    "                        (1),dtype='float32'\n",
    "                    )\n",
    "                    eid=vggextract(x[index])\n",
    "                    #eid=vec_reader(x[index]+'.txt')\n",
    "                    #eid=np.reshape(eid,(1,vec_len))\n",
    "                    encoder_input_data.append(eid)\n",
    "                    for tt in range(t):\n",
    "                        did[tt]=float(token[y[index][tt]])\n",
    "                    dtd[0]=float(token[y[index][t]])\n",
    "                    decoder_input_data.append(did)\n",
    "                    decoder_target_data.append(dtd)\n",
    "                    if len(encoder_input_data)==batch_size:\n",
    "                        yield ([np.array(encoder_input_data),np.array(decoder_input_data)],np.array(decoder_target_data))\n",
    "                        decoder_input_data=[]\n",
    "                        decoder_target_data=[]\n",
    "                        encoder_input_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=256\n",
    "encode_input=Input(shape=(vec_len,))\n",
    "encode_dense=Dense(latent_dim,activation='relu')(encode_input)\n",
    "#encode_dense=Reshape((1,latent_dim))(encode_dense)\n",
    "encode_dense=RepeatVector(1)(encode_dense)\n",
    "decode_input=Input(shape=(seq_len,))\n",
    "decode_emb=Embedding(num_tokens+1,latent_dim,input_length=(seq_len))(decode_input)\n",
    "decoder_vec=concatenate([decode_emb,encode_dense],axis=1)\n",
    "decoder=LSTM(latent_dim)(decoder_vec)\n",
    "decoder=Dense(num_tokens,activation='softmax')(decoder)\n",
    "model=Model([encode_input,decode_input],decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppx(y_true, y_pred):\n",
    "     loss = K.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "     perplexity = K.cast(K.pow(math.e, K.mean(loss, axis=-1)), K.floatx())\n",
    "     return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=ppx, optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "82783/82783 [==============================] - 3557s 43ms/step - loss: 525189.3511 - acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      "82783/82783 [==============================] - 3557s 43ms/step - loss: 496203.8144 - acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      "82783/82783 [==============================] - 3556s 43ms/step - loss: 479043.2914 - acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      "82783/82783 [==============================] - 3558s 43ms/step - loss: 521280.9565 - acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      "82783/82783 [==============================] - 3557s 43ms/step - loss: 537205.2470 - acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      "82783/82783 [==============================] - 3558s 43ms/step - loss: 546644.9061 - acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      "82783/82783 [==============================] - 3557s 43ms/step - loss: 575411.7190 - acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      "82783/82783 [==============================] - 3557s 43ms/step - loss: 537917.1786 - acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      "82783/82783 [==============================] - 3573s 43ms/step - loss: 531968.5134 - acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      "82783/82783 [==============================] - 3581s 43ms/step - loss: 538802.4695 - acc: 0.0000e+00\n",
      "Epoch 11/200\n",
      "82783/82783 [==============================] - 3581s 43ms/step - loss: nan - acc: 0.2862\n",
      "Epoch 12/200\n",
      "82783/82783 [==============================] - 3593s 43ms/step - loss: 11856.9941 - acc: 1.0000\n",
      "Epoch 13/200\n",
      "82783/82783 [==============================] - 3591s 43ms/step - loss: 11856.9941 - acc: 1.0000\n",
      "Epoch 14/200\n",
      "82783/82783 [==============================] - 3591s 43ms/step - loss: 11856.9941 - acc: 1.0000\n",
      "Epoch 15/200\n",
      "82783/82783 [==============================] - 3592s 43ms/step - loss: 11856.9941 - acc: 1.0000\n",
      "Epoch 16/200\n",
      "82783/82783 [==============================] - 3591s 43ms/step - loss: 11856.9941 - acc: 1.0000\n",
      "Epoch 17/200\n",
      " 8133/82783 [=>............................] - ETA: 53:58 - loss: 11856.9941 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    dataGenerator(train_x_file,train_y_seq),\n",
    "    #validation_data=dataGenerator(vali_x_file,vali_y_seq),\n",
    "    steps_per_epoch=((len(train_x_file))//batch_size),\n",
    "    #steps_per_epoch=10000,\n",
    "    #validation_steps=1,\n",
    "    epochs=200\n",
    "    #callbacks=[cbes]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(detokenfile):\n",
    "    with open(detokenfile,'rb') as file:\n",
    "        detoken=pickle.load(file)\n",
    "else:\n",
    "    detoken=dict((i,char) for char,i in token.items())\n",
    "    with open(detokenfile,'wb') as file:\n",
    "        pickle.dump(detoken,file)\n",
    "\n",
    "def decode(code,seq,seq_index,sentence):\n",
    "    decode_token_index=np.argmax(model.predict([code,seq])[0])\n",
    "    seq[0][seq_index]=decode_token_index\n",
    "    sampled_char=detoken[decode_token_index]\n",
    "    sentence+=(\" \"+sampled_char)\n",
    "    if seq_index+1==seq_len or sampled_char='\\n':\n",
    "        return sentence\n",
    "    else:\n",
    "        return decode(code,seq,seq_index+1,sentence)\n",
    "    \n",
    "indices=random.sample(range(len(vali_x_file)),32)\n",
    "for index in indices:\n",
    "    code=vggextract(vali_x_file[index])\n",
    "    code=np.reshape(code,(1,code.shape[0]))\n",
    "    did=np.zeros(\n",
    "        (seq_len),dtype='float32'\n",
    "    )\n",
    "    did=np.reshape(did,(1,did.shape[0]))\n",
    "    did[0][0]=float(token['\\t'])\n",
    "    sentence=decode(code,did,1,\"\")\n",
    "    print(\"-\")\n",
    "    print(\"Input\")\n",
    "    plt.imshow(np.asarray(Image.open(vali_x_file[index])))\n",
    "    plt.show()\n",
    "    print(\"Decoded sentence:\",sentence)\n",
    "    print(\"should be:\",vali_y_seq_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
